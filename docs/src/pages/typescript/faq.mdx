# FAQ

Questions and answers about the SDK. If you have any more questions email aljadery@usc.edu or sidshr@stanford.edu.

## Difference from Anthropic official SDKs

Anthropic's SDKs do not provide the ability to chat, and include `HUMAN_PROMPT` and `AI_PROMPT`.

To better understand their SDK, view their [docs](https://docs.anthropic.com/claude/reference/getting-started-with-the-api).

## What is the tokenizer used?

Anthropic uses the same tokenizer as OpenAI - [tiktoken](https://github.com/openai/tiktoken).

Tiktoken is a fast BPE tokeniser that is very common.

## Bedrock vs Anthropic Console?

Bedrock is hosted by AWS is very similar to the API provided by Anthropic. AWS Bedrock also allows you to provision your own instances to mitigate downtime.

Note: the models are the exact same, it's just who hosts them.
